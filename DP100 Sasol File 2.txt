Dp100-> Day 2
-> Quick summary of ML
-> Deployment of pipelines-> doing today
-> More DS (notebooks), Data Engineering 

https://github.com/a-forty-two/cylons
https://github.com/MicrosoftLearning/DP100 <- ALL LABS are important 

AutomatedML-> 'bestModel' -> 93-95% accuracy 

portal.azure.com
ml.azure.com => ML studio 

y = mx + c
diagnosis = weights * (radi... fract_dim) + bias 


2 ways: new algo from scratch (advanced)-> matrix, pnc, linear alegbra, 
	set theory, graph theory, probability, data structures-> tree, DAG
-> Scikitlearn, Keras -> prebuilt models -> this notebook data.csv

ACI-> single vm cost (min 4 cores) 
AKS -> always available (running VM cost per core X 12 cores)
Pipeline Execution (Batch Processes) 

2 kinds of metrics to LOG in a RUN:
1) FLOAT/INT/DECIMAL-> for plotting purposes
2) string -> for LOGGING purpose not plotting

https://github.com/a-forty-two/sasoldp100

https://notebooks.azure.com/shanuapril/projects/shinchan

RUN:
-> Initialize a run
-> LOG everything (otherwise printed)
-> Dump your model in file system
-> Register your model in the run
-> run.complete()


 registering ONLY the best model


********* Early Stopping- Hyperdrive*****

AutomatedML -> TIME and Min_performance_threshold

all POOR RUNS were dropped 

Python (SDK): [RUN dropping algos]
- Bandit Policy (formula-> slack factor/amount)
- Truncation Policy (Min_performance_threshold)
- Median Policy (all 50% poor performers dropped)
- None

- DELAY_EVALUATION: to create some RUN history so that
best and worst runs can be isolated
	-> 5 
- EVALUATION_INTERVAL-> how frequently the RUNS are
	evaluated -> 1 -> every run!



Hyperparter selection:
-> brute force-> GRID SEARCH -> exhaustive TRUTH table and respective
outputs for HYperparams! -> by min or max that output, you could 
select best hyperparams! 
-> faster approach-> Randomized Search-> 'workable' set of Hyperparams
not the best set. 


https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters

for R programmers: https://azure.github.io/azureml-sdk-for-r/index.html


Resume-> 1:50 
-> Grid Search quick recap 
	-> SARIMAX for time series 

Storages:
- Blob- linked-list or flat storage (large IoT => low cost)
vs
- Data lake - heirarchial or tree storage (Enterprise IoT, comparitively expensive than blob)
	- enables Access Control List (who can access what precisely)
	-> CONTAINERS-> not FOLDERS 
		- contain folders
		- File Systems 
		- independent security, access, encryption etc.
			-> Shared Access Signature (temp access) 
		- account level access possible bypassing all rules
			-> Account.key

Share blobs with users-> SAS
Longer auth of apps -> account key 

- Tables -> NOSQL tables (small IoT data)

- Files -> SMB file sharing 

- Queue -> Inter-az app communication for FCFS messages 
	-> whenever a new message arrives, analyze it's sentiment 
	-> Az Storage Queue + MS Cognitive Services 



Replication:
Web Dev-> Replicate where the users are-> Geo, Locally, Regional/Zonal

Data Collection-> Read-level GENERAL Availability throughout
	-> RA-GRS (read access globally redundant)
	-> cheaper than GRS, read availability during FAILURE

Data Analysis-> lowest cost -> locally redundant
	-> LRS (locally redundant)


********* Data Factory********
- For ELT operations
- ETL can also be done-> using Data Flow (E-> transform -> before load)
- helps build Pipelines and for orchestration or workflows
- can invoke other azure/on-prem/other-cloud components (with permission)

predefined Interation Runtimes -> SQL server or mysql or mongodb
or hbase or S3 or GCP BigQuery-> every thing is PRE CONFIGURED


JSON-> web 
CSV-> IoT
Avro-> streaming (games/IoT)
Parquet-> Apache Spark 
ORC-> optimized rows & cols 


Triggers: -> when to automatically run the pipeline
	- Event-> blob created/deleted
	- Schedule -> sun at 6 pm 
	- Tumbling Window-> LONGER schedules (small batches) 

Billing-> each pipeline EXECUTION




- data sql-> hosted in a VM could be data source!

******* Edge Computing ********
-> Intelligence is running on device itself(y=mx+c-> extracted model) 
	=> network unavailability
	=> quick decisions, no latency
	=> private intelligence (no server/cloud involved)

-> Edge = Server + Client but on DEVICE ITSELF!

=> RaspberryPi=> Linux/Windows=> Py Flask API
				=> Client app 

Hospital Bed
	=> heartbeat sensor-> heart stroke-> IMMEDIATE ACTION!
			-> Client App to activate bed position
			-> send out SMS/notification/calls to concerned attendents
	=> sneeze sensor-> event -> stored locally and analyze later

-> AI-> Monitor, Secure and upgrade the model post deployment 
	- often hard coded -> https://github.com/jedijulia/porter-stemmer
	-> we need cloud to periodically update info on parameters above
-> Deployment-> FPGA-> Field Programmable Gate Arrays  
	

IoT hub v/s Event Hub

-> bidirection v/s Uni-direction
-> cloud to device and device to cloud; v/s only source to destination

Big Data-> Volume, Variety, Velocity

Welcome to day 3! we'll get started shortly!

Agenda:
1) Data Analysis-> more data engineering components
2) ML Studio-> ALL pipeline functionality review
	+ DataDrift 
3) little bit of AI (just to get the feel)
4) anything else you'd like (out of course topics included)
	(let me know by break time-> so that we can make time for it)
5) Exam overview 
	- Adaptive Learning => tough questions is a good news
	- 700 out of 1000-> pass
	- 3 hours including setup time (closed book)
	- 32 - 48 questions 
	- Data Scientist Associate-> no labs, 
	- scenario based questions 
		-> passage, data visualization, data preview, basic analysis
		-> decision-> what solution to use, how would you 
			design/implement 
	- operations & security based questions
	- MCQ (single or multiple correct), arrange in the right 
		sequence, fill in the blanks (drop downs),
		YES/NO-> problem statement-> a solution statement
			- whether solution is right 
			- you cannot review or go back
eg... 
	We have to implement SSL security in ACI
	- solution-> go to portal and upload the SSL certificate
	- log into SSH and then configure SSL 
	AKS-> kubernetes 
	Scalability-> cluster autoscaler for AKS

******* Data Analysis*********
DataBricks-> Apache Spark + DbUtils (data brick utilities)
	-> SQL (HIVE, PIG), PySpark, R, Scala 
Spark-> In memory calculation (Disk also)
	-> SparkContext(everything in RAM), SQLContext(HIVE) -> batch,
		StreamContext -> consuming stream

- clusters
	- standard
	- high concurrency -> shared infra for multiple teams 
		-> data scientists, data analysts, test a model

-> DataBricks (Participate in orchestration, workflow creation) 

https://adb-4306270620392202.2.azuredatabricks.net/?o=4306270620392202

?o=digits -> URL params 
Security-> Az Secret page (not available in UI) to interact with KeyVault
	?o=4306270620392202#secrets/createScope

keyVault Scope-> 



- Data Drift 
- Alerts, logs and Monitoring 
- AI on Azure-> using predefined models (good to know, out of DP100
	beyond general reference) 

Data Scinece Virtual machines
https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/tools-included
Most tools-> LINUX 





********** Security************
Any Az Storage resource-> Failover-> Primary key becomes secondary,
	and secondary becomes primary. Secondary readonly becomes
read/write and vice versa. 

https://docs.microsoft.com/en-us/azure/azure-databricks/store-secrets-azure-key-vault
Key Vault-> meant to store SECRETS
	- connection strings, account keys,certificates  
	- doesn't include-> user passwords
	- Replaced only at RUNTIME-> directly in RAM
	- supports HARDWARE SECURITY MODULE-> HSM
Soft delete-> recycle bin-> files can be restored 

Retention period (days)-> 90 days (example)

Purge protection-> cannot del a res. for <Retntn period> no. of days

	-> ready made AI -> GK level only (AI100)
	-> Alerts, Logging and Monitoring 

Secrets-> certificates (file upload) or Manual (connection string, keys, SAS)
	-> Account URL: jackfruit.blob.core.windows.net
	-> Container: bca
	-> filename: data.csv 
	-> Key1: HbEfeH5DD/JpIuXnS5NJ47CNeZ8hD7bLyylxioBBsTS7RzrPSHyvZFH5EC7apzzHx0u3rjH5tJ85BYeBQL1Ayg==
Key Vault:
	- Secret key: williamwallace (given to data analyst or devs)
	- KeyVault: https://kublaikahn.vault.azure.net/
	- ResourceID: /subscriptions/353b9ff5-223a-4dc4-853e-825bc329d30c/resourceGroups/panda/providers/Microsoft.KeyVault/vaults/kublaikahn
DataBricks:
	- Scope name: robinhood
	- ?o=digitis#secrets/createScope (will be done by DBricks admin)
	
Big data-> how much RAM to select?
	-> at least 3 copies of your data
	-> 100MB-> in ram-> 300 MB
	-> 1 GB-> in ram-> 3 GB
	-> 1 TB-> 3 TB ram-> multiple machines (RAM is additive) 


Logging and Monitoring
	- Log Analytics: strings-> search 
	- Monitor : metrics-> plot
		- Application Insights

3 targets -> 
	- Analyze it right now-> Log Analytics and Monitor
	- Analyze it later -> BLOB Storage 
	- Stream it to other resources-> Event Hub

3:50 <- resuming time 



VMs-> installed a Monitoring Software in a parallel VM
App Services-> PaaS -> no console access
	-> MONITORING via Application Insights 

AI-> rest endpoints-> App Services-> monitored by App Insights 

App Services and DOCKER Containers/Azure COmpute Instance-> App Insights
Virtual Machines -> set it up manually


Entire ML on command line (no portal): az extension add -n azure-cli-ml
https://docs.microsoft.com/en-us/azure/machine-learning/reference-azure-machine-learning-cli


******* Data Monitoring-> Data Drift*********
Challenge-> Data Changes over a period of time 
 -> helps calculate a tiny error on time function 
 -> calculating drift on training v/s inference data 


**** IMPORTANT- ML Pipeline options ******

Convert To Indicator values-> LABEL ENCODING
	[ 'Cape Town', 'Bengaluru'] -> [0, 1]

Conver data into Bins-> Frequency distributions, histograms etc.

Stratified v/s SMOTE -> 
distributing underpresented classes v/s generating data for them 

SMOTE-> tries to find central tendency-> and updates underrepr. label
	accordingly
X     Y    SMOTE    Xnew   Ynew
100   20    100% -> 100     66 (approx)
            200% -> 100     85 (approx)
	    300% -> 100     120 (imblanced again!) 
SMOTE more than 200% is NOT recommended 
https://docs.microsoft.com/en-us/azure/machine-learning/algorithm-module-reference/smote


ANOVA v/s Linear Disc. Analasys -> discrete v/s continous data

Some SPECIAL MODELS:
	-> score Matchbox -> recommendation engine
	-> Pytorch -> special model training 
	-> computer vision -> special model 
	-> CLUSTER -> K Means 
	-> Analmoly Detection-> Fraud Detection, user behavior, malware analysis 

https://github.com/MicrosoftLearning/DP100


Brute Force-> SSH enable (22 port)
	-> linux file system=> pipeline modules
	-> pid -> Kubernetes 

****Out of course*********

-> SNAIL-> 10m/s-> 33-> 1187 
	every second-> speed reduced by half
 how many seconds-> will it travel 20 metres?

x + x/2 + x/4....
-> 3 -> oversampling 

Pandas DF v/s Spark DF-> DF-> single machine v/s CLUSTERS
	- Pandas->smaller size (cannot exceed Ram of 1 machine)
https://www.kdnuggets.com/2016/01/python-data-science-pandas-spark-dataframe-differences.html
Deployments-> Portal/SDK/API-> resources
	Portal-> Fixed settings/limited options
	SDK/API-> ALL the configurations/custom configurations
	Custom Deployment-> TEMPLATES (UI/JSON/Azure-> CMD/bash/ps)

https://docs.microsoft.com/en-us/azure/architecture/best-practices/data-partitioning


Variety-> (out of DP100)
	- Telemetry-> thermometer-> temp, primary measure of device
	- Operational -> monitoring, security, battery status, 
		health of components
	- Configuration/Lifecycle-> Firmware, Remote control, enabling ports
		- on/ff
-> MQTT-> message queue transmissions,
 AMQP-> advanced messaging queuing protocol 


BCA ML problem in Scala(Apache Spark)-> https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/596816822991964/251039699341097/1899624237163506/latest.html


2 kinds of programming languages:
	- imperative v/s declarative 
-> how to do, and what to do  - what to do, computer will decide how to
-> C++, Python, C, assembly    - HTML, neural networks, CSS, PySpark, TensorFlow, Scala

		             Imp           Dec
a=1             a=?           1             ok 
b=2             b=?           2             ok
c=a+b           c=?           3             ok
print(c)        print c       3             do_the_calc()->3


Declarative Languages-> Directed Acyclic GRAPH (LAZY EVALUATION)
Python (ease of coding) -> precompiled C++ (performance)



*** Time series analysis**

COMPLEX GRAPH-> 
	-> SEASONS or PERIOD or REPEATATION
	-> direction in which was traveling 
		-> slope of each point
	-> external factors: NOISE or RESIDUE 

BREAK the graph down-> Seasons, Trend, Residue/Noise 

AR I MA -> Auto Regressions integrated Moving Averages

Hyperparameters:
-> All graphs are NOT perfect-> all our factors may not always play role
example possibility:
better predictions with just Auto Regression on Seasons, and maybe
Moving Averages on Residue-> then what was the use of trend?

hyper-> whether to use these algos or not-> COMBINATIONS 

GRID SEARCH SPACE-> exhaustively create a TRUTH table (1-0) w.r.t. HPs
GRID Search Function-> a metric to maximize/minimize
Hypothetical grid search:
AR I MA  S (p, d, q) => AIC (minimize)
1  0  1  (1, 1, 0, 1) => 128 (algo 1)
0 1  1   (1, 1, 1, 1) => 178 (algo 2)
0 0 1    (0, 1, 0 ,1 )=> exception-> invalid RUN (cancelled RUN)
....
....

because 128 < 178 (AIC), hence algo 1 is better than algo 2

https://towardsdatascience.com/random-search-vs-grid-search-for-hyperparameter-optimization-345e1422899d
